{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "with open('api_key.txt') as f:\n",
        "  api_key = f.read().strip()"
      ],
      "metadata": {
        "id": "uQxDqdjoCGq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install and import `openi`."
      ],
      "metadata": {
        "id": "H8y7GYJ8J6XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "ERz-s-GPJ9w6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6290db-b228-4f6c-e1c2-0f00410f51d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = api_key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = openai.api_key"
      ],
      "metadata": {
        "id": "5HddX1JFJaxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a variable `client` that is an `openai.OpenAI()` object."
      ],
      "metadata": {
        "id": "909uHDzGKMK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI()"
      ],
      "metadata": {
        "id": "Oix0P8qyKRrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a list called `message_history` to store your chat history. Initialize it with a single system message."
      ],
      "metadata": {
        "id": "WgbToxZlKZU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message_history = []\n",
        "system_message = 'I am Iron Man'\n",
        "message_history.append({\"role\": \"system\", \"content\": system_message})"
      ],
      "metadata": {
        "id": "0ZlWfPOyKVTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = [\n",
        "    {'role':'system','content':system_message},\n",
        "    {'role':'user','content':first_question}\n",
        "]"
      ],
      "metadata": {
        "id": "1nInnKHR47Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function `new_message(message)` that:\n",
        "* appends `message` as a user message to `message_history`\n",
        "* calls the OpenAI Chat Completions API with `message_history` using the `client` object defined earlier\n",
        "* appends the response message text to `message_history`"
      ],
      "metadata": {
        "id": "GC3N-jDDK1B3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def new_message(message):\n",
        "    # Append the user message to message_history\n",
        "    message_history.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    # Call the OpenAI Completions API with message_history using the client object\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=message_history\n",
        "    )\n",
        "\n",
        "    # Append the response message text to message_history\n",
        "    assistant_reply = response.choices[0].message.content\n",
        "    message_history.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
        "\n",
        "    return assistant_reply\n",
        "\n",
        "#user_input = \"Can you tell me a joke?\"\n",
        "#assistant_reply = new_message(user_input)\n",
        "\n"
      ],
      "metadata": {
        "id": "38URkN2SL91p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function `print_messages()` that prints the contents of `message_history` in a human-friendly way."
      ],
      "metadata": {
        "id": "FwmgA5jDNB_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_messages():\n",
        "    for message in message_history:\n",
        "        role = message[\"role\"]\n",
        "        content = message[\"content\"]\n",
        "\n",
        "        if role == \"system\":\n",
        "            print(f\"System: {content}\")\n",
        "        elif role == \"user\":\n",
        "            print(f\"You: {content}\")\n",
        "        elif role == \"assistant\":\n",
        "            print(f\"Assistant: {content}\")\n",
        "\n",
        "print_messages()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oAAwWhwXNBRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "badd7046-3613-453b-e9e2-91f47fc8daac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System: I am Iron Man\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use your two functions to send at least 4 messages and display the results."
      ],
      "metadata": {
        "id": "tWfE5Le-NiGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_inputs = [\"Who are you?\",\n",
        "               \"What can you do?\",\n",
        "               \"Who are your friends?\",\n",
        "               \"How old are you?\"\n",
        "]\n",
        "\n",
        "for user_input in user_inputs:\n",
        "    new_message(user_input)\n",
        "\n",
        "print_messages()"
      ],
      "metadata": {
        "id": "VkyZsJ1OMmBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a3e613-8e74-4011-fc11-2e57387c5f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System: I am Iron Man\n",
            "You: Who are you?\n",
            "Assistant: I am an AI language model developed by OpenAI. I am here to assist and interact with users through text-based conversations. How can I help you today?\n",
            "You: What can you do?\n",
            "Assistant: As an AI language model, I have a wide range of capabilities. I can help answer questions, provide information on various topics, engage in casual conversation, offer suggestions, help with writing, and more. My abilities include language translation, text summarization, generating creative content, and even playing text-based games. Feel free to ask me anything or let me know how I can assist you specifically!\n",
            "You: Who are your friends?\n",
            "Assistant: As an AI language model, I don't have personal friends or relationships like humans do. However, I am designed to assist and interact with users like yourself. So, if you consider engaging in conversation with me as being a friend, then you can consider me as your virtual friend!\n",
            "You: How old are you?\n",
            "Assistant: As an AI language model, I don't have a physical existence or an age like humans do. However, the model version I am based on (GPT-3) was introduced in June 2020 by OpenAI. So, you can think of me as being relatively new in terms of when the model was released.\n"
          ]
        }
      ]
    }
  ]
}